{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An data overview (1ST step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_data = pd.read_csv('mnist_avaliacao.csv', sep=',')\n",
    "test_data = pd.read_csv('mnist_teste.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview types\n",
    "all_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the last columns \n",
    "all_data.dtypes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look at the 'class' balance. I had to rename to 'y_class', because class is already in use in python \n",
    "all_data.y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the minimum value avaible\n",
    "all_data.iloc[:, :-1].min().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the maximum value avaible\n",
    "all_data.iloc[:, :-1].max().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets overview values\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets recover 1 line and try to draw\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from work_methods import matrix_recover\n",
    "\n",
    "# choose a number between 1 and 2050 to draw\n",
    "to_recover = 5\n",
    "square_reference = 28\n",
    "\n",
    "# recover a matrix from data to plot\n",
    "matrix = matrix_recover(all_data, to_recover, square_reference)\n",
    "\n",
    "# heatmap plot of matrix\n",
    "plt.figure(figsize=(28, 28))\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the classifier methods without any input filter (2ND step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import optuna\n",
    "import pandas as pd \n",
    "\n",
    "# python codes\n",
    "from resultado import Fold\n",
    "from avaliacao import Experimento\n",
    "from metodo import ScikitLearnAprendizadoDeMaquina\n",
    "\n",
    "file_name = 'mnist_avaliacao.csv'\n",
    "\n",
    "# define classes\n",
    "numbers_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "numbers_values = [x for x in range(0,10,1)]\n",
    "numbers = dict(zip(numbers_values,numbers_names))\n",
    "\n",
    "# recover DataFrame\n",
    "df_data = pd.DataFrame(pd.read_csv(file_name))\n",
    "\n",
    "#gera o fold e p experimento\n",
    "folds = Fold.gerar_k_folds(df_data,val_k=5,col_classe='y_class',\n",
    "                            num_repeticoes=1,seed=1,\n",
    "                            num_folds_validacao=3,num_repeticoes_validacao=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Classifier 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from avaliacao import OtimizacaoObjetivoRandomForest\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "ml_method = ScikitLearnAprendizadoDeMaquina(clf_rf)\n",
    "exp = Experimento(folds,ml_method, OtimizacaoObjetivoRandomForest, num_trials=10,\n",
    "                    sampler=optuna.samplers.TPESampler(seed=1, n_startup_trials=3))\n",
    "exp.calcula_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studdy_fold_0 = exp.studies_per_fold[0]\n",
    "studdy_fold_0.trials_dataframe().sort_values(\"value\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from work_methods import parameters_graph\n",
    "parameters_graph(exp.studies_per_fold[0].trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from work_methods import show_results\n",
    "show_results(\"Random Forest 28x28\", numbers, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from avaliacao import OtimizacaoObjetivoArvoreDecisao\n",
    "\n",
    "clf_dtree = DecisionTreeClassifier(random_state=1)\n",
    "ml_method = ScikitLearnAprendizadoDeMaquina(clf_dtree)\n",
    "exp = Experimento(folds,ml_method, OtimizacaoObjetivoArvoreDecisao, num_trials=10,\n",
    "                    sampler=optuna.samplers.TPESampler(seed=1, n_startup_trials=3))\n",
    "exp.calcula_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studdy_fold_0 = exp.studies_per_fold[0]\n",
    "studdy_fold_0.trials_dataframe().sort_values(\"value\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_graph(exp.studies_per_fold[0].trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"Decision Tree 28x28\", numbers, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use infogain as input filter (3RD step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganho_informacao import ganho_informacao\n",
    "\n",
    "# naming adjust\n",
    "database = all_data\n",
    "\n",
    "info_gain_database = pd.DataFrame(columns=['Atributo', 'Ganho de Informação'])\n",
    "for column in database.columns:\n",
    "    if column != 'y_class':\n",
    "        info_gain_database.loc[len(info_gain_database)] = {'Atributo': column, 'Ganho de Informação': ganho_informacao(database, 'y_class', column)}\n",
    "\n",
    "print(info_gain_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from work_methods import info_gain_matrix_recover\n",
    "\n",
    "squere_reference = 28\n",
    "\n",
    "info_gain_matrix = info_gain_matrix_recover(info_gain_database, square_reference)\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(29, 29))\n",
    "sns.heatmap(info_gain_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A informação obtida pelo info_gain sugere que as primeira 4 linhas, as primeiras 4 colunas, as últimas 4 linhas e as últimas 4 colunas não são tão expressivas na determinação do dígito. Isso acontece porque as amostras coletadas não fizeram bom uso do espaço disponível tornando os pixels dos cantos irrelevantes. Poderia ser feito um corte mais interessante também arredondando as bordas da matriz, mas isso implicaria em uma matriz deformada. Então essa ideia não será considerada. O plano consiste em apenas fazer as eliminações das linhas e colunas sugeridas, ocorre uma redução de 384 atributos. Antes desse filtro, o total era de 784. Com a eliminação, esse número cai para 400. É uma redução aproximada de 49% dos atributos relevantes e ainda mantém a matriz quadrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features\n",
    "# remove 4 top rows\n",
    "# remove 4 last rows\n",
    "# remove 4 left columns\n",
    "# remove 4 last columns\n",
    "square_reference = 28\n",
    "start_rows = 4\n",
    "start_columns = 4\n",
    "last_rows = 24\n",
    "last_columns = 24\n",
    "\n",
    "# create filter\n",
    "filtr = np.zeros((28,28))\n",
    "for i in range(start_rows, last_rows):\n",
    "    for j in range(start_columns, last_columns):\n",
    "        filtr[i][j] = 1\n",
    "\n",
    "filtr_array = []\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        filtr_array.append(int(filtr[i][j]))\n",
    "        \n",
    "filtr_array.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling file and filter csv\n",
    "new_file = open('mnist_sample_selecaoFeature.csv', 'w')\n",
    "with open('mnist_avaliacao.csv', 'r') as file:\n",
    "    first_row = True\n",
    "    for line in file:\n",
    "        row_to_write = ''\n",
    "        items = line.split(',')\n",
    "        for i in range(len(items)):\n",
    "            if filtr_array[i] == 1:\n",
    "                row_to_write += items[i]+','\n",
    "            elif filtr_array[i] == 2:\n",
    "                row_to_write += items[i]\n",
    "        nan = False\n",
    "        if not first_row:\n",
    "            for item in row_to_write:\n",
    "                if not item.isnumeric() and not item.isalpha() and item!=',' and item!='\\n':\n",
    "                    nan = True\n",
    "        if row_to_write.count(',') == 400 and not nan:\n",
    "            new_file.write(row_to_write)\n",
    "        first_row = False\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv('mnist_sample_selecaoFeature.csv', sep=',')\n",
    "\n",
    "info_gain_database = pd.DataFrame(columns=['Atributo', 'Ganho de Informação'])\n",
    "for column in database.columns:\n",
    "    if column != 'y_class':\n",
    "        info_gain_database.loc[len(info_gain_database)] = {'Atributo': column, 'Ganho de Informação': ganho_informacao(database, 'y_class', column)}\n",
    "\n",
    "print(info_gain_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squere_reference = 20\n",
    "\n",
    "info_gain_matrix = info_gain_matrix_recover(info_gain_database, square_reference)\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(info_gain_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'mnist_sample_selecaoFeature.csv'\n",
    "\n",
    "# recover DataFrame\n",
    "df_data = pd.DataFrame(pd.read_csv(file_name))\n",
    "\n",
    "#gera o fold e p experimento\n",
    "folds = Fold.gerar_k_folds(df_data,val_k=5,col_classe='y_class',\n",
    "                            num_repeticoes=1,seed=1,\n",
    "                            num_folds_validacao=3,num_repeticoes_validacao=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest Classifier 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "ml_method = ScikitLearnAprendizadoDeMaquina(clf_rf)\n",
    "exp = Experimento(folds,ml_method, OtimizacaoObjetivoRandomForest, num_trials=10,\n",
    "                    sampler=optuna.samplers.TPESampler(seed=1, n_startup_trials=3))\n",
    "exp.calcula_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studdy_fold_0 = exp.studies_per_fold[0]\n",
    "studdy_fold_0.trials_dataframe().sort_values(\"value\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_graph(exp.studies_per_fold[0].trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"Random Forest 20x20\", numbers, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dtree = DecisionTreeClassifier(random_state=1)\n",
    "ml_method = ScikitLearnAprendizadoDeMaquina(clf_dtree)\n",
    "exp = Experimento(folds,ml_method, OtimizacaoObjetivoArvoreDecisao, num_trials=10,\n",
    "                    sampler=optuna.samplers.TPESampler(seed=1, n_startup_trials=3))\n",
    "exp.calcula_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studdy_fold_0 = exp.studies_per_fold[0]\n",
    "studdy_fold_0.trials_dataframe().sort_values(\"value\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_graph(exp.studies_per_fold[0].trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"Decision Tree 20x20\", numbers, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Feature as input filter (4TH step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
